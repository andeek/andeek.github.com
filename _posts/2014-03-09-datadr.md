--
layout: post_ak
title: "Reading: datadr - Divide and Recombine in R"
root: "../../../../"
comments: true
---
As part of the course [Stat 585X](http://dicook.github.io/stat585/) I am taking this semester, I will be posting a series of responses to assigned course readings. Mostly these will be my rambling thoughts as I skim papers.

****
This week we are reading documentation on the [datadr](http://hafen.github.io/datadr/) package by Ryan Hafen from February 2014. This tutorial lay outs the introduction to the new package *datadr* as well as some background on the Divide-Recombine strategy that the package is built upon.

###Divide and Recombine (or is it S-A-C?)
The **divide and recombine (D-R)** strategy is very similar to something we have talked about recently: the Split-Apply-Combine paradigm. In fact, the two seem almost identical. The D-R strategy is to take a dataset, split it in a logical way into many chunks (**divide**) and then fit them back together after applying some transformation or summary (**recombine**). Sound familiar? This is the same idea as the S-A-C paradigm, except recombine encompasses both the **apply** and **combine** steps.

<img src="{{ page.root }}images/blog/2014-03-09-datadr/D-R_S-A-C.png" alt="Divide-recombine vs. Split-combine-apply strategy" style="width: 500px;"/>

###Birds of a feather...
So we have a package (*datadr*) based on the D-R strategy and multiple packages (*plyr*, *dplyr*) based on the S-A-C paradigm, which are essentially the same thing. What's the difference between the packages? I would say in some ways *datadr* is more similar to *dplyr* than *plyr*, because

* In *datadr*, divisions are data objects that persist. The authors did this because with very large data, computing a division is expensive compared to recombination. This is similar to *dplyr* in that we can create an object with the *group_by()* function that persists. Often we will use the chaining methods with the *%.%* operator, but if splitting is an expensive operation and we may want to use the splits with different apply statements, keeping the splits around makes sense.
* Both *datadr* and *dplyr* allow for use of the same interface with different backends. For example, *dplyr* is easily used with data in R memory, or with data from a MySQL, SQLite, or postgreSQL database. Similarly, *datadr* can be used with data in R memory, or with data in a Hadoop Distributed File System (HDFS), RHIPE, or Hadoop MapReduce setup. Since *datadr* is already compatible with Hadoop, it would appear that this package has the one up on being able to handle truly **huge** datasets.

However, *datadr* uses key-value pairs as its underlying data structure, which can be arranged in list form. *dplyr* is limited to using a data frame input and output. In this way *datadr* has some similarity to the *plyr* package.

###Side-by-side example
Let's take a look at an example of using both *datadr* and *dplyr* to accomplish the same task. The data is adult income from the 1994 census database, pulled from the (UCI machine learning repository)[http://archive.ics.uci.edu/ml/datasets/Adult].

We'll start with the *datadr* package.

{% highlight r %}
# library(dev_tools) install_github('datadr', 'hafen')
library(datadr)
data(adult)

# turn adult into a ddf
(adultDdf <- ddf(adult, update = TRUE))
{% endhighlight %}



{% highlight text %}
## * Getting basic 'ddo' attributes...
## * Getting basic 'ddf' attributes...
## * Running map/reduce to get missing attributes...
## * Getting basic 'ddo' attributes...
{% endhighlight %}



{% highlight text %}
## 
## Distributed data object of class 'kvMemory' with attributes: 
## 
## 'ddo' attribute | value
## ----------------+-----------------------------------------------------------
##  keys           | keys are available through getKeys(dat)
##  totStorageSize | 2.12 MB
##  totObjectSize  | 2.12 MB
##  nDiv           | 1
##  splitSizeDistn | use splitSizeDistn(dat) to get distribution
##  example        | use kvExample(dat) to get an example subset
##  bsvInfo        | [empty] no BSVs have been specified
## 
## 'ddf' attribute | value
## ----------------+-----------------------------------------------------------
##  vars           | age(int), workclass(fac), fnlwgt(int), and 13 more
##  transFn        | identity (original data is a data frame)
##  nRow           | 32561
##  splitRowDistn  | use splitRowDistn(dat) to get distribution
##  summary        | use summary(dat) to see summaries
## 
## In-memory data connection
{% endhighlight %}



{% highlight r %}
names(adultDdf)
{% endhighlight %}



{% highlight text %}
##  [1] "age"           "workclass"     "fnlwgt"        "education"    
##  [5] "educationnum"  "marital"       "occupation"    "relationship" 
##  [9] "race"          "sex"           "capgain"       "caploss"      
## [13] "hoursperweek"  "nativecountry" "income"        "incomebin"
{% endhighlight %}



{% highlight r %}

library(ggplot2)
edTable <- summary(adultDdf)$education$freqTable
edTable$var <- with(edTable, reorder(var, Freq, mean))
qplot(var, Freq, data = edTable, geom = "point") + coord_flip()
{% endhighlight %}

![center](../../../../../images/blog/2014-03-09-datadr/unnamed-chunk-1.png) 

Let's group the grades together where appropriate and remove preschool. We can make these changes to the education variable within the *divide()* function. Of course, we could do this to the original data in this case, but this is an illustrations. For very large data, it would make more sense (read: be possible) to apply any transformations during the division.

{% highlight r %}
datadr_test <- function() {
    # make a preTransFn to group some education levels
    edGroups <- function(v) {
        v$edGroup <- as.character(v$education)
        v$edGroup[v$edGroup %in% c("1st-4th", "5th-6th")] <- "Some-elementary"
        v$edGroup[v$edGroup %in% c("7th-8th", "9th")] <- "Some-middle"
        v$edGroup[v$edGroup %in% c("10th", "11th", "12th")] <- "Some-HS"
        v
    }
    
    # divide by edGroup and filter out 'Preschool'
    byEdGroup <- divide(adultDdf, by = "edGroup", preTransFn = edGroups, filterFn = function(x) x$edGroup[1] != 
        "Preschool", update = TRUE)
    
    print(byEdGroup)
    
    # tabulate number of people in each education group
    edGroupTable <- recombine(byEdGroup, apply = nrow, combine = combRbind())
    print(edGroupTable)
    
    # order for plotting
    edGroupTable$edGroup <- with(edGroupTable, reorder(edGroup, val, mean))
    print(qplot(edGroup, val, data = edGroupTable, geom = "point") + coord_flip())
}
datadr_test()
{% endhighlight %}



{% highlight text %}
## * Verifying parameters...
## * Applying division...
## * Getting basic 'ddo' attributes...
## * Running map/reduce to get missing attributes...
## * Getting basic 'ddo' attributes...
{% endhighlight %}



{% highlight text %}
## 
## Distributed data object of class 'kvMemory' with attributes: 
## 
## 'ddo' attribute | value
## ----------------+-----------------------------------------------------------
##  keys           | keys are available through getKeys(dat)
##  totStorageSize | 3.3 MB
##  totObjectSize  | 3.3 MB
##  nDiv           | 11
##  splitSizeDistn | use splitSizeDistn(dat) to get distribution
##  example        | use kvExample(dat) to get an example subset
##  bsvInfo        | [empty] no BSVs have been specified
## 
## 'ddf' attribute | value
## ----------------+-----------------------------------------------------------
##  vars           | age(int), workclass(cha), fnlwgt(int), and 13 more
##  transFn        | identity (original data is a data frame)
##  nRow           | 32510
##  splitRowDistn  | use splitRowDistn(dat) to get distribution
##  summary        | use summary(dat) to see summaries
## 
## Division:
##   Type: Conditioning variable division
##     Conditioning variables: edGroup
## 
## In-memory data connection
{% endhighlight %}



{% highlight text %}
## * Verifying suitability of 'apply' for division type...
## * Verifying suitability of 'output' for specified 'combine'...
## * Testing the 'apply' method on a subset...
## * Applying to all subsets...
## * Getting basic 'ddo' attributes...
{% endhighlight %}



{% highlight text %}
##            edGroup   val
## 1       Assoc-acdm  1067
## 2        Assoc-voc  1382
## 3        Bachelors  5355
## 4        Doctorate   413
## 5          HS-grad 10501
## 6          Masters  1723
## 7      Prof-school   576
## 8     Some-college  7291
## 9  Some-elementary   501
## 10         Some-HS  2541
## 11     Some-middle  1160
{% endhighlight %}

![center](../../../../../images/blog/2014-03-09-datadr/unnamed-chunk-2.png) 


Now let's do the same thing with *dplyr*.

{% highlight r %}
library(dplyr)
dplyr_test <- function() {
    byEdGroup_dplyr <- adult %.% mutate(edGroup = ifelse(as.character(education) %in% 
        c("1st-4th", "5th-6th"), "Some-elementary", ifelse(as.character(education) %in% 
        c("7th-8th", "9th"), "Some-middle", ifelse(as.character(education) %in% 
        c("10th", "11th", "12th"), "Some-HS", as.character(education))))) %.% 
        filter(edGroup != "Preschool") %.% group_by(edGroup)
    print(byEdGroup_dplyr)
    
    edGroupTable_dplyr <- byEdGroup_dplyr %.% summarise(count = n())
    print(edGroupTable_dplyr)
    
    # order for plotting
    edGroupTable_dplyr$edGroup <- with(edGroupTable_dplyr, reorder(edGroup, 
        count, mean))
    print(qplot(edGroup, count, data = edGroupTable_dplyr, geom = "point") + 
        coord_flip())
}
dplyr_test()
{% endhighlight %}



{% highlight text %}
## Source: local data frame [32,510 x 17]
## Groups: edGroup
## 
##    age        workclass fnlwgt education educationnum
## 1   39        State-gov  77516 Bachelors           13
## 2   50 Self-emp-not-inc  83311 Bachelors           13
## 3   38          Private 215646   HS-grad            9
## 4   53          Private 234721      11th            7
## 5   28          Private 338409 Bachelors           13
## 6   37          Private 284582   Masters           14
## 7   49          Private 160187       9th            5
## 8   52 Self-emp-not-inc 209642   HS-grad            9
## 9   31          Private  45781   Masters           14
## 10  42          Private 159449 Bachelors           13
## .. ...              ...    ...       ...          ...
## Variables not shown: marital (fctr), occupation (fctr), relationship
##   (fctr), race (fctr), sex (fctr), capgain (int), caploss (int),
##   hoursperweek (int), nativecountry (fctr), income (fctr), incomebin
##   (dbl), edGroup (chr)
## Source: local data frame [11 x 2]
## 
##            edGroup count
## 1       Assoc-acdm  1067
## 2        Assoc-voc  1382
## 3        Bachelors  5355
## 4        Doctorate   413
## 5          HS-grad 10501
## 6          Masters  1723
## 7      Prof-school   576
## 8          Some-HS  2541
## 9     Some-college  7291
## 10 Some-elementary   501
## 11     Some-middle  1160
{% endhighlight %}

![center](../../../../../images/blog/2014-03-09-datadr/unnamed-chunk-3.png) 

As you can see, pretty similar in idea and in execution. We can check the speed of each method.

{% highlight r %}
library(profr)
datadr_prof <- profr(datadr_test())
{% endhighlight %}



{% highlight text %}
## * Verifying parameters...
## * Applying division...
## * Getting basic 'ddo' attributes...
## * Running map/reduce to get missing attributes...
## * Getting basic 'ddo' attributes...
## * Verifying suitability of 'apply' for division type...
## * Verifying suitability of 'output' for specified 'combine'...
## * Testing the 'apply' method on a subset...
## * Applying to all subsets...
## * Getting basic 'ddo' attributes...
{% endhighlight %}

![center](../../../../../images/blog/2014-03-09-datadr/unnamed-chunk-41.png) 

{% highlight r %}
dplyr_prof <- profr(dplyr_test())
{% endhighlight %}

![center](../../../../../images/blog/2014-03-09-datadr/unnamed-chunk-42.png) 

*datadr* took 1.7 seconds, while *ddply* took 0.26 seconds. That's a 84.71% speedup over *datadr* in this example. 

###Takeaways
It seems like both *datadr* and *dplyr* have their benefits. Of course, this example is almost a joke because of everything is small enough to fit in memory. I'd like to test these packages on a much bigger dataset and see what I think after that. The ability of using Hadoop with *datadr* is an attractive one, although I don't anticipate ever having me hands on data big enough to use it to it's fullest capability. Both are interesting packages building on a sound principle and I look forward to using both more.

