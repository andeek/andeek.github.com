--
layout: post_ak
title: "Reading: datadr - Divide and Recombine in R"
root: "../../../../"
comments: true
---

As part of the course [Stat 585X](http://dicook.github.io/stat585/) I am taking this semester, I will be posting a series of responses to assigned course readings. Mostly these will be my rambling thoughts as I skim papers.

****
This week we are reading documentation on the [datadr](http://hafen.github.io/datadr/) package by Ryan Hafen from February 2014. This tutorial lay outs the introduction to the new package *datadr* as well as some background on the Divide-Recombine strategy that the package is built upon.

###Divide and Recombine (or is it S-A-C?)
The **divide and recombine (D-R)** strategy is very similar to something we have talked about recently: the Split-Apply-Combine paradigm. In fact, the two seem almost identical. The D-R strategy is to take a dataset, split it in a logical way into many chunks (**divide**) and then fit them back together after applying some transformation or summary (**recombine**). Sound familiar? This is the same idea as the S-A-C paradigm, except recombine encompasses both the **apply** and **combine** steps.

<img src="{{ page.root }}images/blog/2014-03-09-datadr/D-R_S-A-C.png" alt="Divide-recombine vs. Split-combine-apply strategy" style="width: 500px;"/>

###Birds of a feather...
So we have a package (*datadr*) based on the D-R strategy and multiple packages (*plyr*, *dplyr*) based on the S-A-C paradigm, which are essentially the same thing. What's the difference between the packages? I would say in some ways *datadr* is more similar to *dplyr* than *plyr*, because

* In *datadr*, divisions are data objects that persist. The authors did this because with very large data, computing a division is expensive compared to recombination. This is similar to *dplyr* in that we can create an object with the *group_by()* function that persists. Often we will use the chaining methods with the *%.%* operator, but if splitting is an expensive operation and we may want to use the splits with different apply statements, keeping the splits around makes sense.
* Both *datadr* and *dplyr* allow for use of the same interface with different backends. For example, *dplyr* is easily used with data in R memory, or with data from a MySQL, SQLite, or postgreSQL database. Similarly, *datadr* can be used with data in R memory, or with data in a Hadoop Distributed File System (HDFS), RHIPE, or Hadoop MapReduce setup. Since *datadr* is already compatible with Hadoop, it would appear that this package has the one up on being able to handle truly **huge** datasets.

However, *datadr* uses key-value pairs as its underlying data structure, which can be arranged in list form. *dplyr* is limited to using a data frame input and output. In this way *datadr* has some similarity to the *plyr* package.

###Side-by-side example
Let's take a look at an example of using both *datadr* and *dplyr* to accomplish the same task. The data is adult income from the 1994 census database, pulled from the (UCI machine learning repository)[http://archive.ics.uci.edu/ml/datasets/Adult].

We'll start with the *datadr* package.

{% highlight r %}
# library(dev_tools) install_github('datadr', 'hafen')
library(datadr)
{% endhighlight %}



{% highlight text %}
## Error: there is no package called 'datadr'
{% endhighlight %}



{% highlight r %}
data(adult)
{% endhighlight %}



{% highlight text %}
## Warning: data set 'adult' not found
{% endhighlight %}



{% highlight r %}

# turn adult into a ddf
(adultDdf <- ddf(adult, update = TRUE))
{% endhighlight %}



{% highlight text %}
## Error: could not find function "ddf"
{% endhighlight %}



{% highlight r %}
names(adultDdf)
{% endhighlight %}



{% highlight text %}
## Error: object 'adultDdf' not found
{% endhighlight %}



{% highlight r %}

library(ggplot2)
edTable <- summary(adultDdf)$education$freqTable
{% endhighlight %}



{% highlight text %}
## Error: object 'adultDdf' not found
{% endhighlight %}



{% highlight r %}
edTable$var <- with(edTable, reorder(var, Freq, mean))
{% endhighlight %}



{% highlight text %}
## Error: object 'edTable' not found
{% endhighlight %}



{% highlight r %}
qplot(var, Freq, data = edTable, geom = "point") + coord_flip()
{% endhighlight %}



{% highlight text %}
## Error: object 'edTable' not found
{% endhighlight %}

Let's group the grades together where appropriate and remove preschool. We can make these changes to the education variable within the *divide()* function. Of course, we could do this to the original data in this case, but this is an illustrations. For very large data, it would make more sense (read: be possible) to apply any transformations during the division.

{% highlight r %}
datadr_test <- function() {
    # make a preTransFn to group some education levels
    edGroups <- function(v) {
        v$edGroup <- as.character(v$education)
        v$edGroup[v$edGroup %in% c("1st-4th", "5th-6th")] <- "Some-elementary"
        v$edGroup[v$edGroup %in% c("7th-8th", "9th")] <- "Some-middle"
        v$edGroup[v$edGroup %in% c("10th", "11th", "12th")] <- "Some-HS"
        v
    }
    
    # divide by edGroup and filter out 'Preschool'
    byEdGroup <- divide(adultDdf, by = "edGroup", preTransFn = edGroups, filterFn = function(x) x$edGroup[1] != 
        "Preschool", update = TRUE)
    
    print(byEdGroup)
    
    # tabulate number of people in each education group
    edGroupTable <- recombine(byEdGroup, apply = nrow, combine = combRbind())
    print(edGroupTable)
    
    # order for plotting
    edGroupTable$edGroup <- with(edGroupTable, reorder(edGroup, val, mean))
    print(qplot(edGroup, val, data = edGroupTable, geom = "point") + coord_flip())
}
datadr_test()
{% endhighlight %}



{% highlight text %}
## Error: could not find function "divide"
{% endhighlight %}


Now let's do the same thing with *dplyr*.

{% highlight r %}
library(dplyr)
{% endhighlight %}



{% highlight text %}
## 
## Attaching package: 'dplyr'
## 
## The following objects are masked from 'package:stats':
## 
##     filter, lag
## 
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
{% endhighlight %}



{% highlight r %}
dplyr_test <- function() {
    byEdGroup_dplyr <- adult %.% mutate(edGroup = ifelse(as.character(education) %in% 
        c("1st-4th", "5th-6th"), "Some-elementary", ifelse(as.character(education) %in% 
        c("7th-8th", "9th"), "Some-middle", ifelse(as.character(education) %in% 
        c("10th", "11th", "12th"), "Some-HS", as.character(education))))) %.% 
        filter(edGroup != "Preschool") %.% group_by(edGroup)
    print(byEdGroup_dplyr)
    
    edGroupTable_dplyr <- byEdGroup_dplyr %.% summarise(count = n())
    print(edGroupTable_dplyr)
    
    # order for plotting
    edGroupTable_dplyr$edGroup <- with(edGroupTable_dplyr, reorder(edGroup, 
        count, mean))
    print(qplot(edGroup, count, data = edGroupTable_dplyr, geom = "point") + 
        coord_flip())
}
dplyr_test()
{% endhighlight %}



{% highlight text %}
## Error: object 'adult' not found
{% endhighlight %}

As you can see, pretty similar in idea and in execution. We can check the speed of each method.

{% highlight r %}
library(profr)
datadr_prof <- profr(datadr_test())
{% endhighlight %}



{% highlight text %}
## Error: arguments imply differing number of rows: 0, 2
{% endhighlight %}



{% highlight r %}
dplyr_prof <- profr(dplyr_test())
{% endhighlight %}



{% highlight text %}
## Error: arguments imply differing number of rows: 0, 2
{% endhighlight %}

*datadr* took 

{% highlight text %}

Error in eval(expr, envir, enclos) : object 'datadr_prof' not found

{% endhighlight %}

 seconds, while *ddply* took 

{% highlight text %}

Error in eval(expr, envir, enclos) : object 'dplyr_prof' not found

{% endhighlight %}

 seconds. That's a 

{% highlight text %}

Error in eval(expr, envir, enclos) : object 'datadr_prof' not found

{% endhighlight %}

% speedup over *datadr* in this example. 

###Takeaways
It seems like both *datadr* and *dplyr* have their benefits. Of course, this example is almost a joke because of everything is small enough to fit in memory. I'd like to test these packages on a much bigger dataset and see what I think after that. The ability of using Hadoop with *datadr* is an attractive one, although I don't anticipate ever having me hands on data big enough to use it to it's fullest capability. Both are interesting packages building on a sound principle and I look forward to using both more.

